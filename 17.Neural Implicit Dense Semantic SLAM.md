# Neural Implicit Dense Semantic SLAM

## 摘要和介绍

- 文章主旨

  提出了一个用于室内场景的实时RGBD VSLAM算法。

  - 这个算法可以高内存效率的学习室内场景的三维几何特征 和 语义分割。
  - 这个算法包含3个部分
    1. 跟踪（ORB-SLAM3）
    2. 回环（ORB-SLAM3）
       - 为了解决Nice-SLAM和E-SLAM的中tracking drift的问题
    3. 建图（神经辐射场）
       - 建图网络为了实时性，所以使用Instant-NGP的backbone
       - 建图网络为了可以学习环境的有向距离场(SDF)，所以基于[NeuS](https://github.com/Totoro97/NeuS)来修改

- 文章贡献

  1. 提出了一个实时算法，使用关键帧来优化建图网络
     - 关键帧的选取标准 参照(orb-slam3)
  2. 提出了一个稠密三维语义分割的方法，基于关键帧的二维语义颜色图
  3. 建图包含了SDF，semantics，RGB，和深度信息
     - 高内存效率：25平方的房间需要的内存<25MB
  4. 通过将大场景划分成一个个子空间，并优化各个子空间，来达到将本文的方法从室内推广到了大场景
  5. 验证了本文方法在只有RGB特征时同样稳定

- 相关工作的缺点

  - lsd-slam， orb-slam 建图都是点云
  - iMAP，NICE-SLAM，和ESLAM稠密重建做的不错，但是
    1. 不够实时
    2. 不适合大场景
    3. 使用相同的网络训练位姿和建图可能会陷入局部最优解

## 方法

### 1. Mapping

- 网络结构：

  使用[instant-ngp](https://nvlabs.github.io/instant-ngp/)作为backbone，为了实时性

  根据[NeuS](https://github.com/Totoro97/NeuS)来修改网络，为了学习环境的有向距离场

- 和Neus一样，本文使用**体渲染**来计算颜色和深度的估计值

  给定相机位置$\mathbf{o}$ 和 光线方向$\mathbf{v}$

  1. 在光线上采样n个点

     $\mathbf{p}(t_i)=\mathbf{o}+t_i\mathbf{v},\ i=1,\cdots,n$

  2. 颜色和深度的估计值
     $$
     \hat{I}=\sum_{i=1}^{n}T_i\alpha_ic_i\ \ and \ \ \hat{d}=\sum_{i=1}^{n}T_i\alpha_it_i \tag{1}
     $$

     - $T_i=\prod_{j=1}^{i-1}$：累积透射比accumulated transmittance

     - $\alpha_i$：不透明度opacity
       $$
       \alpha_i=max\bigg(\frac{\Phi_s(f(\mathbf{p}(t_i)))-\Phi_s(f(\mathbf{p}(t_{i+1})))}{\Phi_s(f(\mathbf{p}(t_i)))},0\bigg) \tag{2}
       $$

       - $f(\cdot)$：SDF函数
       - $\Phi_s(\cdot)$：sigmoid函数

- **损失函数**
  $$
  \begin{align}
  L&=L_{photometric}+L_{geometric}\\
  &=\sum_{p}||I_{gt}(p)-\hat{I}(p)||_1+\sum_{p}||d_{gt}(p)-\hat{d}(p)||_2
  \end{align} \tag{3}
  $$

  - gt： 相机读到的rgbd值
  - 深度项只有在深度值非0时计算

- 此时网络生成的地图包含：

  rgb, 深度，和常规地图

### 2. Keyframe selection

根据[ORB_SLAM3](https://github.com/UZ-SLAMLab/ORB_SLAM3)的标准选择关键帧

### 3. 3D semantic segmentation

- 作者的方法：只需要使用关键帧的2维语义分割信息，就可以学习场景的3D语义信息

  - 在mapping网络中加一个decoder网络：common geometry block

  - encoder：将二维语义分割图编码为颜色图colormaps

    作者认为：神经辐射场在学习3D场景的颜色时很强，只用颜色图就足以语义分割。

- pipline

  1. 使用二维语义分割网络来得到每一关键帧的二维语义分割

  2. 将语义分割转为颜色图

  3. 在上面3式(损失函数)的基础上再加一个语义分割损失来优化神经辐射场网络
     $$
     L=\sum_{p}||I_{gt}(p)-\hat{I}(p)||_1+\sum_{p}||d_{gt}(p)-\hat{d}(p)||_2+\sum_{p}||s_{gt}(p)-\hat{s}(p)||_2\tag{4}
     $$

     - 首先将未知的语义标签全都转为黑色
     - 深度项只有在深度值非0时计算

     - 只对有颜色的像素计算语义损失

  4. 优化后，神经辐射场网络可以生成带语义信息的颜色图

### 4. Online RGBD pipeline

1. 将RGB和depth图传给ORB-SLAM3，实现跟踪，局部建图和回环

2. 由ORB-SLAM3维护一个动态的关键帧集合

3. 从关键帧集合中随机的选取关键帧来优化网络，新加入的关键帧有更高的权重被选取到

4. 建图

5. 使用 active/non-active mesh 来实现快速重定位。

   ORB-SLAM3 在 tracking 断了后，会：

   - 将 active mesh 保存到内存中。
   - 创建一个新的 network。
   - 使用保存的 active mesh 来优化网络。
   - 使用优化后的网络来进行重定位。

### 5. Extension to large scenes

- ORB-SLAM在tracking部分可以处理大场景
- 问题在建图方面，解决方法：
  1. 给予orb-slam的是全局空间S，将全局空间S划分为多个子空间$S_i$，子空间是5x5x5立方米的立方体并以立方体的中心$c_i$表示
  2. 每一个子空间都有独立的关键帧集合，每当ORB-SLAM检测到新的关键帧，就会利用back-projection找到这个关键帧(相机)所属于的子空间。
  3. 每一个子空间的mapping network都是独立优化的
  4. 最后将这些子图整合到一起

